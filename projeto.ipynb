{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "source": [
    "## Lendo o dump de documentos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numero de documentos: 11225\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('dump_small.jsonln', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "print(f'Numero de documentos: {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['title', 'body'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para encontrar links HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseado em https://gist.github.com/gruber/249502\n",
    "def rm_htmlLinks(texto):\n",
    "    return re.sub(r\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\", \"\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para limpar os wikilinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_links(texto):\n",
    "    return re.sub(r\"\\[\\[(?:[^|]*?\\|)*?([^|]*?)\\]\\]\", r\"\\1\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para limpar os templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_templates(texto):\n",
    "    count = 0\n",
    "    spansToRemove = []\n",
    "    for item in re.finditer(r\"{{|}}\", texto):\n",
    "        if item[0] == \"{{\":\n",
    "            if count == 0:\n",
    "                begin = item.span()[0]\n",
    "            count += 1\n",
    "        else:\n",
    "            count -= 1\n",
    "            if count == 0:\n",
    "                end = item.span()[1]\n",
    "                spansToRemove.append((begin, end))\n",
    "    cleanText = \"\"\n",
    "    begin = 0\n",
    "    for span in spansToRemove:\n",
    "        end, nextBegin = span\n",
    "        cleanText += texto[begin:end]\n",
    "        begin = nextBegin\n",
    "    cleanText += texto[begin:]\n",
    "    return cleanText"
   ]
  },
  {
   "source": [
    "## Função para remover as ocorrências de ```{|...|}```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_templates2(texto):\n",
    "    count = 0\n",
    "    spansToRemove = []\n",
    "    for item in re.finditer(r\"{[\\|]|[\\|]}\", texto):\n",
    "        if item[0] == \"{|\":\n",
    "            if count == 0:\n",
    "                begin = item.span()[0]\n",
    "            count += 1\n",
    "        else:\n",
    "            count -= 1\n",
    "            if count == 0:\n",
    "                end = item.span()[1]\n",
    "                spansToRemove.append((begin, end))\n",
    "    cleanText = \"\"\n",
    "    begin = 0\n",
    "    for span in spansToRemove:\n",
    "        end, nextBegin = span\n",
    "        cleanText += texto[begin:end]\n",
    "        begin = nextBegin\n",
    "    cleanText += texto[begin:]\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para remover as ocorrências de ```<ref>...</ref>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_refs(texto):\n",
    "    return re.sub(r\"<ref.*>.*</ref>|<ref.*>|</ref>\", \"\", texto)"
   ]
  },
  {
   "source": [
    "## Função pare remover as demais ocorrências de tags HTML"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_htmlTags(texto):\n",
    "    return re.sub(r\"<.*?>|</.*?>\", \"\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para remover as ocorrências de aspas (simples ou dupla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_aspas(texto):\n",
    "    return re.sub(r\"(['\\\"]+)(.*?)\\1\", r\"\\2\", texto)"
   ]
  },
  {
   "source": [
    "## Função para remover caracteres de pontuação ou semelhantes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_caracterPontuacao(texto):\n",
    "    sem_travessao = re.sub(r\"\\s\\-\\s|\\-\\-+\", \" \", texto)\n",
    "    return re.sub(r\"[^\\w\\s\\-]\", \" \", sem_travessao)"
   ]
  },
  {
   "source": [
    "## Função para remover as palavras que contém números"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_digitos(texto):\n",
    "    return re.sub(r\"\\w*\\d\\w*\", \"\", texto)"
   ]
  },
  {
   "source": [
    "## Função para remover os travessões não hífen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_travessaoErrado(texto):\n",
    "    return re.sub(r\"(\\w+)\\-|\\-(\\w+)\", r\"\\1\\2\", texto)"
   ]
  },
  {
   "source": [
    "## Função para remover palavras contendo caracteres fora do alfabeto português"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_notLatin(texto):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\u00B5-\\u00FF\\s]\", r\"\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_textos(txt):\n",
    "    output = rm_htmlLinks(txt)\n",
    "    output = sub_links(output)\n",
    "    output = rm_refs(output)\n",
    "    output = rm_htmlTags(output)\n",
    "    output = rm_templates(output)\n",
    "    output = rm_templates2(output)\n",
    "    output = rm_aspas(output)\n",
    "    output = rm_caracterPontuacao(output)\n",
    "    output = rm_digitos(output)\n",
    "    output = rm_travessaoErrado(output)\n",
    "    output = rm_notLatin(output)\n",
    "    return output.lower()"
   ]
  },
  {
   "source": [
    "## Exemplo do resultado da limpeza"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nalexandre é um prenome popular da língua portuguesa  é cognato ao nome alexander  da língua inglesa  em países lusófonos  pessoas chamadas alexandre são normalmente apelidadas de alex \n\n   origem   \no nome deriva do latim alexander  romanização do nome grego   aléksandros   etimologicamente  o nome seria um composto do verbo   aléksein   defender  e o substantivo   andrós   genitivo de   anr   homem  assim  pode ser traduzido como protetor da humanidade \n\no termo seria ou um tipo raro de composto tatpurusha invertido  com o modificante na segunda posição  o tatpurusha cognato em sânscrito sendo  nararaka  cf  ramayana     o equivalente exato em sânscrito seria  rakinara  do pie hleks i hnros  ou um composto gasto do tipo terpsimbrotos  cujo significado original seria ele protege os homens \n\no primeiro registro conhecido do nome foi feito no grego micênico  encontrouse a versão feminina do nome  alexandra  escrito em linear b \n\no nome era um dos títulos  epítetos  dados à deusa grega hera  na ilíada  o personagem páris também é conhecido como alexandre  a popularidade do nome se espalhou pelo mundo grego através das conquistas militares do rei alexandre iii da macedônia  comumente chamado de alexandre  o grande  posteriormente  diversos alexandres receberam seus nomes em homenagem direta ou indireta a ele \n\nna rússia o nome era razoavelmente raro até o período do czar alexandre i da rússia  a partir do qual se tornou um dos primeiros nomes mais comuns do país  ganhando um número considerável de variações e abreviações \n\n   variações em outros idiomas   \n  albanês   aleksandër  aleks  leka i madh  lekë  no norte da albânia   sandër  skëndër  skander  ver skanderbeg \n  amárico   eskender\n  árabe        iskandar   skandar  skender\n  bielorrusso   p  aliaksandr   e  ales     alyelka \n  catalão   alexandre  àlex  xandre\n  inglês   alexander  alec  alex  sandy  andy  alexis  alexa  sandra  xander\n  gaélico escocês   alasdair  alastair  alistair  alisdair\n  galego   alexandre  álex\n  georgiano     alexandre     aleko     lekso     sandro \n  hebraico     alexander \n  hindi   hindustani   sikandar\n  iídiche      sender  senderl\n  irlandês   alasandar\n  italiano   alessandro  leandro  ale  sandro  alessio  lissandro\n  malaio   iskandar\n  língua malaiala        chandy \n  maltês   lixandru\n  quirguiz     skender \n  persa     eskandar \n  russo     alexandr \n  sânscrito   alekchendra\n  ucraniano     oleksandr \n  urdu   skender  sikandar  sikander  sikandereazam é alexandre  o grande \n  uzbeque   iskandar\n  turco iskander\n\n   pessoas   \n  alexandre de afrodísias  filósofo da escola peripatética\n  alexandre da macedônia \n  alexandre de gusmão\n  alexandre balas\n  alexandre de mindos\n  alexandre i da iugoslávia\n  alexandre ii karadjordjevitch chefe da casa de karaorevi da sérvia\n  papa alexandre cognome de vários papas  como santo alexandre\n  alexandre da rússia cognome de vários imperadores da rússia  alexandre i da rússia   alexandre ii da rússia   alexandre iii da rússia \n  alexandre da escócia cognome de vários reis da escócia  alexandre i da escócia   alexandre ii da escócia   alexandre iii da escócia \n  alexis ii  patriarca de moscou \n  santo alexandre cognome de vários santos e mártires\n\n   filmes   \n  alexandre  o grande coprodução hispanoestadunidense de  \n  alexandre produção estadunidense de  \n\n\n\n\n\ncategoria prenomes\n"
     ]
    }
   ],
   "source": [
    "print(limpa_textos(data[0][\"body\"]))"
   ]
  },
  {
   "source": [
    "## Calcula frequência absoluta de cada palavra"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_palavras(docs):\n",
    "    output = {}\n",
    "    for doc in docs:\n",
    "        words = limpa_textos(doc[\"body\"]).split()\n",
    "        for word in words:\n",
    "            if word in output.keys():\n",
    "                output[word] += 1\n",
    "            else:\n",
    "                output[word] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "159980\nWall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "palavras = define_palavras(data)\n",
    "print(len(palavras))"
   ]
  },
  {
   "source": [
    "## Define o vocabulário com as 10 mil palavras mais frequentes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_palavras = dict(sorted(palavras.items(), key=lambda item: -item[1]))\n",
    "vocab = list(sort_palavras.items())[:10000]\n",
    "vocab = dict(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWERCASE = [chr(x) for x in range(ord('a'), ord('z') + 1)]\n",
    "LOWERCASE_OTHERS = ['ç', 'á', 'â', 'é', 'ã', 'õ', 'ê', 'í', 'ú', 'ô', 'ó']  # etc.\n",
    "LETTERS = LOWERCASE + LOWERCASE_OTHERS\n",
    "\n",
    "def edit1(text):\n",
    "    words = []\n",
    "    \n",
    "    # Fase 1: as remoçoes.\n",
    "    for p in range(len(text)):\n",
    "        new_word = text[:p] + text[p + 1:]\n",
    "        if len(new_word) > 0:\n",
    "            words.append(new_word)\n",
    "        \n",
    "    # Fase 2: as adições.\n",
    "    for p in range(len(text) + 1):\n",
    "        for c in LETTERS:\n",
    "            new_word = text[:p] + c + text[p:]\n",
    "            words.append(new_word)\n",
    "    \n",
    "    # Fase 3: as substituições.\n",
    "    for p in range(len(text)):\n",
    "        orig_c = text[p]\n",
    "        for c in LETTERS:\n",
    "            if orig_c != c:\n",
    "                new_word = text[:p] + c + text[p + 1:]\n",
    "                words.append(new_word)\n",
    "    \n",
    "    return set(words)\n",
    "\n",
    "def edit2(text):\n",
    "    words1 = edit1(text)\n",
    "    words2 = set()\n",
    "    for w in words1:\n",
    "        candidate_words2 = edit1(w)\n",
    "        candidate_words2 -= words1\n",
    "        words2.update(candidate_words2)\n",
    "    words2 -= set([text])\n",
    "    return words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidatos(palavra):\n",
    "    if palavra in vocab:\n",
    "        candidatos = [palavra]\n",
    "    else:\n",
    "        candidatos = []\n",
    "        dist1 = [w for w in edit1(palavra) if w in vocab]\n",
    "        if len(dist1) > 0:\n",
    "            candidatos += dist1\n",
    "        else:\n",
    "            dist2 = [w for w in edit2(palavra) if w in vocab]\n",
    "            candidatos += dist2 + [palavra]\n",
    "    return candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    scanner = re.Scanner(\n",
    "            [\n",
    "                (r\"\\d+\", lambda scanner, token: (\"NUM\", token)),\n",
    "                (r\"[.,\\/#!$%\\^&\\*;:{}=\\-_`~()]\", lambda scanner, token: (\"SPECIAL\", token)),\n",
    "                (r\"[^.,\\/#!$%\\^&\\*;:{}=\\-_`~()\\d]+\", lambda scanner, token: (\"WORD\", token)),\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "    results = scanner.scan(txt)[0]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado de https://norvig.com/spell-correct.html\n",
    "def probability(palavra, N=sum(vocab.values())):\n",
    "    if palavra in vocab:\n",
    "        return vocab[palavra] / N\n",
    "    else:\n",
    "        return 1 / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referência: https://norvig.com/spell-correct.html\n",
    "def corrige(txt):\n",
    "    frase = txt.split()\n",
    "    output = \"\"\n",
    "    for palavra in frase:\n",
    "        tokens = tokenize(palavra)\n",
    "        for tk in tokens:\n",
    "            if tk[0] == \"WORD\":\n",
    "                if tk[1].lower() in stopwords.words(\"portuguese\"):\n",
    "                    output += tk[1]\n",
    "                else:\n",
    "                    candidates = candidatos(tk[1].lower())\n",
    "                    if tk[1][0].isupper():\n",
    "                        output += max(candidates, key=probability).capitalize()\n",
    "                        \n",
    "                    else:\n",
    "                        output += max(candidates, key=probability)\n",
    "            else:\n",
    "                output += tk[1]\n",
    "        output += \" \"\n",
    "    return output[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3 pratos de trigo, para ter tigre testes!!!'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "corrige(\"3 pratos de trigo, para três tigres tristes!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}